package domain.training

import domain.data.LinearAlgebra.{Matrix, Vector}
import domain.network.Network

/**
 * Container for the gradients of a single layer.
 *
 * @param wGrad The gradient matrix for the weights.
 * @param bGrad The gradient vector for the biases.
 */
case class LayerGradient(wGrad: Matrix, bGrad: Vector)

/**
 * Container for the gradients of the entire network, holding a [[LayerGradient]] for each layer.
 */
case class NetworkGradient(layers: List[LayerGradient])


/**
 * Interface for the objective function to be minimized during training.
 */
trait LossFunction:

  /**
   * Calculates the scalar error value indicating how far the prediction is from the target.
   *
   * @param predicted The output vector generated by the neural network.
   * @param target    The expected output.
   * @return A [[Double]] representing the magnitude of the error.
   */
  def compute(predicted: Vector, target: Vector): Double

  /**
   * Computes the gradient of the loss function with respect to the network's output.
   *
   * @param predicted The output vector generated by the neural network.
   * @param target    The expected output.
   * @return A [[Vector]] representing direction and magnitude of the correction needed.
   */
  def derivative(predicted: Vector, target: Vector): Vector


/**
 * Interface for weight regularization strategies.
 * Regularization helps prevent overfitting by penalizing large weights.
 */
trait RegularizationStrategy:
  /**
   * Applies the regularization penalty to the weights.
   *
   * @param weights      The current weight matrix of a specific layer.
   * @param learningRate The current learning rate used to scale the penalty strength.
   * @return The new weight [[Matrix]] with the regularization term applied.
   */
  def apply(weights: Matrix, learningRate: Double): Matrix


/**
 * Interface for the optimization algorithm.
 * Encapsulates the logic for updating the network parameters
 * using the computed gradients.
 */
trait Optimizer:
  /**
   * Performs a single optimization step.
   * Applies the calculated gradients to the current network parameters to produce the next state.
   *
   * @param network   The current state of the neural network.
   * @param gradients The gradients calculated via backpropagation.
   * @return A new [[Network]] instance with updated weights and biases.
   */
  def updateWeights(network: Network, gradients: NetworkGradient): Network
